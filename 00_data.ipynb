{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> How to prepare dataset for our experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torchtext\n",
    "\n",
    "from inspect import signature\n",
    "from fastai.text.all import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to generate text pairs using Fast.AI library?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to show how we could use the low-level API provided by Fast.AI to build a custom dataset for our task.\n",
    "- We want to identify if a pair of text are duplicate of each other or not.\n",
    "- The data format would be something like ((t1, t2), label), where t1 and t2 represent the text and label represents a boolean variable indicating whether they are duplicate or not.\n",
    "- We will make use of the transforms provided by Fast.AI to build the dataset and dataloaders required by our model to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceSimTuple(fastuple):\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        df = pd.DataFrame({'a': [self[0]],\n",
    "                           'b': [self[1]]\n",
    "                          })\n",
    "        display_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPairGetter(ItemTransform):\n",
    "    def __init__(self, s1='a', s2='b',target='target'):\n",
    "        store_attr('s1,s2,target')\n",
    "    def encodes(self, o): \n",
    "        return o[self.s1], o[self.s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOWVectorizer(ItemTransform):\n",
    "    def __init__(self, vec):\n",
    "        store_attr('vec')\n",
    "    \n",
    "    def encodes(self, o):\n",
    "        ftok = self.vec.transform(np.array([o[0]]))\n",
    "        stok = self.vec.transform(np.array([o[1]]))\n",
    "        return ftok.toarray() * 1., stok.toarray() * 1.\n",
    "    \n",
    "    def decodes(self, o):\n",
    "        forig = self.vec.inverse_transform(o[0])\n",
    "        sorig = self.vec.inverse_transform(o[1])\n",
    "        return SentenceSimTuple((TitledStr(' '.join(forig[0])), TitledStr(' '.join(sorig[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame({'a': ['this is a good life', 'slow life', 'am i good', 'waiting for'],\n",
    "                       'b': ['take it easy', 'I am on the moon, rythm is right.', 'truely madly', 'for waiting'],\n",
    "                       'target': [0, 1, 0, 1]\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec  = CountVectorizer()\n",
    "vec  = vec.fit(sample['a'].tolist() + sample['b'].tolist())\n",
    "dset = Datasets(sample, [[TextPairGetter(), BOWVectorizer(vec)], [ItemGetter('target'), Categorize()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dset.decode(dset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life slow</td>\n",
       "      <td>am is moon on right rythm the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "show_at(dset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dset.dataloaders(bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tuple: [{tuple: [torch.Tensor, torch.Tensor]},\n",
       "  fastai.torch_core.TensorCategory]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls._types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to override show_batch method for our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def show_batch(x:tuple, y, samples, ctxs=None, max_n=10, trunc_at=150, **kwargs):\n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    if isinstance(samples[0][0], tuple):\n",
    "        samples = L((*s[0], *s[1:]) for s in samples)\n",
    "        if trunc_at is not None: samples = L((s[0].truncate(trunc_at), s[1].truncate(trunc_at), *s[2:]) for s in samples)\n",
    "    if trunc_at is not None: samples = L((s[0].truncate(trunc_at),*s[1:]) for s in samples)\n",
    "    \n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    display_df(pd.DataFrame(ctxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>am good</td>\n",
       "      <td>madly truely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for waiting</td>\n",
       "      <td>for waiting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Questions Pair Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2751</td>\n",
       "      <td>5459</td>\n",
       "      <td>5460</td>\n",
       "      <td>What is the reason behind having one small testicle and b=one bigger comparatively?</td>\n",
       "      <td>What is the reason behind having one small testicle and other is bigger comparatively?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129269</td>\n",
       "      <td>207694</td>\n",
       "      <td>207695</td>\n",
       "      <td>How do I build up a readership for my blog?</td>\n",
       "      <td>What are some ways of gauging the readership of a blog?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157094</td>\n",
       "      <td>245715</td>\n",
       "      <td>245716</td>\n",
       "      <td>Should company provide a signed job offer letter or email job offer should be fine?</td>\n",
       "      <td>Will IT companies call me for sure if I have offer letter provided by them?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111342</td>\n",
       "      <td>182406</td>\n",
       "      <td>182407</td>\n",
       "      <td>Can a F1 student visa holder become a Uber driver in USA?</td>\n",
       "      <td>Can I drive for Uber with my H1-B work visa or F1 student visa in the US?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157746</td>\n",
       "      <td>246570</td>\n",
       "      <td>246571</td>\n",
       "      <td>When can we expect APPSC Group-I/II notification?</td>\n",
       "      <td>What is the ratio for APPSC AE notification?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2  \\\n",
       "0    2751    5459    5460   \n",
       "1  129269  207694  207695   \n",
       "2  157094  245715  245716   \n",
       "3  111342  182406  182407   \n",
       "4  157746  246570  246571   \n",
       "\n",
       "                                                                             question1  \\\n",
       "0  What is the reason behind having one small testicle and b=one bigger comparatively?   \n",
       "1                                          How do I build up a readership for my blog?   \n",
       "2  Should company provide a signed job offer letter or email job offer should be fine?   \n",
       "3                            Can a F1 student visa holder become a Uber driver in USA?   \n",
       "4                                    When can we expect APPSC Group-I/II notification?   \n",
       "\n",
       "                                                                                question2  \\\n",
       "0  What is the reason behind having one small testicle and other is bigger comparatively?   \n",
       "1                                 What are some ways of gauging the readership of a blog?   \n",
       "2             Will IT companies call me for sure if I have offer letter provided by them?   \n",
       "3               Can I drive for Uber with my H1-B work visa or F1 student visa in the US?   \n",
       "4                                            What is the ratio for APPSC AE notification?   \n",
       "\n",
       "   is_duplicate  \n",
       "0             1  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR      = Path('~/data/dl_nlp')\n",
    "RAW_DATA_PATH = BASE_DIR / 'data' / 'quodup'\n",
    "\n",
    "\n",
    "train       = pd.read_csv(RAW_DATA_PATH / 'train.csv')\n",
    "train       = train.sample(frac=1.)\n",
    "train.index = np.arange(len(train))\n",
    "\n",
    "# fill empty questions with ''\n",
    "train.loc[:, 'question1'] = train.question1.fillna('')\n",
    "train.loc[:, 'question2'] = train.question2.fillna('')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 3.14 s, total: 19.9 s\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "%%time\n",
    "\n",
    "splits      = IndexSplitter(np.arange(len(train)-int(.2 * len(train)), len(train)))(train)\n",
    "combined_df = pd.DataFrame({'text': list(train.iloc[splits[0]]['question1'].unique()) + list(train.iloc[splits[0]]['question2'].unique())})\n",
    "_, cnt      = tokenize_df(combined_df, text_cols='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NumericalizePair(Numericalize):\n",
    "    def encodes(self, o): \n",
    "        return TensorText(tensor([self.o2i  [o_] for o_ in o['q1']])), TensorText(tensor([self.o2i  [o_] for o_ in o['q2']])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 7.18 s, total: 1min 35s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dset = Datasets(train, [[Tokenizer.from_df('question1', tok_text_col='q1'), Tokenizer.from_df('question2', tok_text_col='q2'), \n",
    "                          NumericalizePair(vocab=list(cnt.keys()))], [ItemGetter('is_duplicate'), Categorize()]], splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorText([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  8, 14, 15, 16]),\n",
       "  TensorText([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11, 590,   3,\n",
       "           14,  15,  16])),\n",
       " TensorCategory(1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('x x b o s   x x m a j   w h a t   i s   t h e   r e a s o n   b e h i n d   h a v i n g   o n e   s m a l l   t e s t i c l e   a n d   b   =   o n e   b i g g e r   c o m p a r a t i v e l y   ?',\n",
       "  'x x b o s   x x m a j   w h a t   i s   t h e   r e a s o n   b e h i n d   h a v i n g   o n e   s m a l l   t e s t i c l e   a n d   o t h e r   i s   b i g g e r   c o m p a r a t i v e l y   ?'),\n",
       " '1')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.decode(dset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pad_Chunk_Pair(ItemTransform):\n",
    "    \"Pad `samples` by adding padding by chunks of size `seq_len`\"\n",
    "    def __init__(self, pad_idx=1, pad_first=True, seq_len=72,decode=True,**kwargs):\n",
    "        store_attr('pad_idx, pad_first, seq_len,seq_len')\n",
    "        super().__init__(**kwargs)\n",
    "    def before_call(self, b):\n",
    "        \"Set `self.max_len` before encodes\"\n",
    "        xas, xbs = [], []\n",
    "        for xs in b:\n",
    "            xa, xb = xs[0]\n",
    "            if isinstance(xa, TensorText):\n",
    "                xas.append(xa.shape[0])\n",
    "            if isinstance(xb, TensorText):\n",
    "                xbs.append(xb.shape[0])\n",
    "        \n",
    "        self.max_len_a = max(xas)\n",
    "        self.max_len_b = max(xbs)\n",
    "        \n",
    "    def __call__(self, b, **kwargs):\n",
    "        self.before_call(b)\n",
    "        return super().__call__(tuple(b), **kwargs)\n",
    "    \n",
    "    def encodes(self, batch):\n",
    "        texts  = ([s[0][0] for s in batch], [s[0][1] for s in batch])\n",
    "        labels = default_collate([s[1:] for s in batch])\n",
    "        \n",
    "        inps   = {}\n",
    "        \n",
    "        pa = default_collate([pad_chunk(ta,pad_idx=self.pad_idx, pad_first=self.pad_first, seq_len=self.seq_len, pad_len=self.max_len_a) for ta in texts[0]])\n",
    "        pb = default_collate([pad_chunk(tb,pad_idx=self.pad_idx, pad_first=self.pad_first, seq_len=self.seq_len, pad_len=self.max_len_b) for tb in texts[1]])\n",
    "        \n",
    "        inps['pa'] = pa\n",
    "        inps['pb'] = pb\n",
    "        \n",
    "        if len(labels):\n",
    "            inps['labels'] = labels[0]\n",
    "        \n",
    "        res = (inps, )\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Undict(Transform):\n",
    "    def decodes(self, x:dict):\n",
    "        if 'pa' in x and 'pb' in x: res = (x['pa'], x['pb'], x['labels'])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len    = 72\n",
    "dls_kwargs = {\n",
    "              'before_batch': Pad_Chunk_Pair(seq_len=seq_len),\n",
    "              'after_batch': Undict(),\n",
    "              'create_batch': fa_convert\n",
    "             }\n",
    "\n",
    "dls        = dset.dataloaders(bs=128, seq_len=seq_len, **dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'pa': TensorText([[  0,   1,   2,  ...,   1,   1,   1],\n",
       "          [  0,   1,  17,  ...,   1,   1,   1],\n",
       "          [  0,   1,  38,  ...,   1,   1,   1],\n",
       "          ...,\n",
       "          [  0,   1, 189,  ...,   1,   1,   1],\n",
       "          [  0,   1,  17,  ...,   1,   1,   1],\n",
       "          [  0,   1, 170,  ...,   1,   1,   1]], device='cuda:0'),\n",
       "  'pb': TensorText([[  0,   1,  18,  ...,   1,   1,   1],\n",
       "          [  0,   1,  17,  ...,   1,   1,   1],\n",
       "          [  0,   1,  18,  ...,   1,   1,   1],\n",
       "          ...,\n",
       "          [  0,   1, 189,  ...,   1,   1,   1],\n",
       "          [  0,   1,  38,  ...,   1,   1,   1],\n",
       "          [  0,   1, 170,  ...,   1,   1,   1]], device='cuda:0'),\n",
       "  'labels': TensorCategory([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "          0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "          1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "          0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')},)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorText([[  0,   1,   2,  ...,   1,   1,   1],\n",
       "          [  0,   1,  17,  ...,   1,   1,   1],\n",
       "          [  0,   1,  38,  ...,   1,   1,   1],\n",
       "          ...,\n",
       "          [  0,   1, 189,  ...,   1,   1,   1],\n",
       "          [  0,   1,  17,  ...,   1,   1,   1],\n",
       "          [  0,   1, 170,  ...,   1,   1,   1]]),\n",
       "  TensorText([[  0,   1,  18,  ...,   1,   1,   1],\n",
       "          [  0,   1,  17,  ...,   1,   1,   1],\n",
       "          [  0,   1,  18,  ...,   1,   1,   1],\n",
       "          ...,\n",
       "          [  0,   1, 189,  ...,   1,   1,   1],\n",
       "          [  0,   1,  38,  ...,   1,   1,   1],\n",
       "          [  0,   1, 170,  ...,   1,   1,   1]]),\n",
       "  TensorCategory([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "          0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "          1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "          0, 0, 0, 0, 1, 0, 0, 0])),)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd = dls.decode(x)\n",
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dataset():\n",
    "    BASE_DIR      = Path('~/data/dl_nlp')\n",
    "    RAW_DATA_PATH = BASE_DIR / 'data' / 'quodup'\n",
    "\n",
    "\n",
    "    train       = pd.read_csv(RAW_DATA_PATH / 'train.csv')\n",
    "    train       = train.sample(frac=1.)\n",
    "    train.index = np.arange(len(train))\n",
    "\n",
    "    # fill empty questions with ''\n",
    "    train.loc[:, 'question1'] = train.question1.fillna('')\n",
    "    train.loc[:, 'question2'] = train.question2.fillna('')\n",
    "    \n",
    "    return train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
