{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove embeddings and match pyramid\n",
    "\n",
    "> How to load glove embeddings and implement Match Pyramid Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torchtext\n",
    "\n",
    "from inspect import signature\n",
    "from fastai.text.all import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from matchpyramid.data import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "train = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "\n",
    "splits      = IndexSplitter(np.arange(len(train)-int(.2 * len(train)), len(train)))(train)\n",
    "combined_df = pd.DataFrame({'text': list(train.iloc[splits[0]]['question1'].unique()) + list(train.iloc[splits[0]]['question2'].unique())})\n",
    "_, cnt      = tokenize_df(combined_df, text_cols='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "dset = Datasets(train, [[Tokenizer.from_df('question1', tok_text_col='q1'), Tokenizer.from_df('question2', tok_text_col='q2'), \n",
    "                          NumericalizePair(vocab=list(cnt.keys()))], [ItemGetter('is_duplicate'), Categorize()]], splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "seq_len    = 72\n",
    "dls_kwargs = {\n",
    "              'before_batch': Pad_Chunk_Pair(seq_len=seq_len),\n",
    "              'after_batch': Undict(),\n",
    "              'create_batch': fa_convert\n",
    "             }\n",
    "\n",
    "dls        = dset.dataloaders(bs=128, seq_len=seq_len, **dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dls():\n",
    "    train       = load_dataset()\n",
    "    splits      = IndexSplitter(np.arange(len(train)-int(.2 * len(train)), len(train)))(train)\n",
    "    \n",
    "    combined_df = pd.DataFrame({'text': list(train.iloc[splits[0]]['question1'].unique()) + list(train.iloc[splits[0]]['question2'].unique())})\n",
    "    _, cnt      = tokenize_df(combined_df, text_cols='text')\n",
    "    dset = Datasets(train, [[Tokenizer.from_df('question1', tok_text_col='q1'), Tokenizer.from_df('question2', tok_text_col='q2'), \n",
    "                          NumericalizePair(vocab=list(cnt.keys()))], [ItemGetter('is_duplicate'), Categorize()]], splits=splits)\n",
    "    seq_len    = 72\n",
    "    dls_kwargs = {\n",
    "                  'before_batch': Pad_Chunk_Pair(seq_len=seq_len),\n",
    "                  'after_batch': Undict(),\n",
    "                  'create_batch': fa_convert\n",
    "                 }\n",
    "\n",
    "    dls        = dset.dataloaders(bs=128, seq_len=seq_len, **dls_kwargs)\n",
    "    return dls, cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloveEmbeddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_glove_embeddings():\n",
    "    return torchtext.vocab.GloVe(name = '6B', dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400000, 100])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "# Pretrained word vectors/embeddings\n",
    "glove = get_glove_embeddings()\n",
    "glove.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_my_vocab(cnt):\n",
    "    return torchtext.vocab.vocab(cnt, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "my_vocab = get_my_vocab(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convert_cnt_to_glove_emb(my_vocab):\n",
    "    return glove.get_vecs_by_tokens(my_vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('disprove',\n",
       " tensor([-0.5153,  0.8319,  0.2246, -0.7387,  0.1872,  0.2602, -0.4256,  0.6712,\n",
       "         -0.3108, -0.6127,  0.0895, -0.2401,  1.1878,  0.6761, -0.0229, -0.9253,\n",
       "          0.0712,  0.3884, -0.4292,  0.3714,  0.3267,  0.4314,  0.8749,  0.3401,\n",
       "         -0.2319, -0.4114,  0.4906, -0.3291, -0.4911, -0.1899,  0.3341, -0.2124,\n",
       "         -0.3839, -0.0805,  1.1161,  0.2362,  0.3133,  0.4929,  0.1000, -0.1513,\n",
       "         -0.1418, -0.2802, -0.2388, -0.3549,  0.1828, -0.1913,  0.6054,  0.0746,\n",
       "         -0.2073, -0.6097,  0.1991, -0.5702, -0.1743,  1.4419, -0.2502, -1.8648,\n",
       "          0.4167, -0.2461,  1.5010,  0.8741, -0.6714,  1.2762, -0.2721,  0.1758,\n",
       "          1.2242,  0.2824,  0.6237,  0.6395,  0.3691, -0.8468, -0.3227, -0.6715,\n",
       "         -0.1963, -0.4079, -0.2097, -0.1962,  0.0419,  0.5397, -1.1105, -0.3952,\n",
       "          0.6659, -0.2330, -1.0820,  0.0465, -2.0993, -0.2849,  0.0800, -0.1296,\n",
       "         -0.3001, -0.4676, -0.8183, -0.0485, -0.3223, -0.3201, -1.1207, -0.0568,\n",
       "         -0.7300, -1.2024,  1.1304,  0.3479]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "my_vocab.vectors = convert_cnt_to_glove_emb(my_vocab)\n",
    "my_vocab.get_itos()[13], my_vocab.vectors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MatchPyramid(Module):\n",
    "  \n",
    "    def __init__(self, vocab, max_len):\n",
    "        vocab_size, emb_size = vocab.vectors.shape\n",
    "        self.max_len = max_len\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size, _weight=vocab.vectors)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=8,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding=0,\n",
    "                                 bias=True\n",
    "                                 )\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=8,\n",
    "                                     out_channels=16,\n",
    "                                     kernel_size=(3, 3),\n",
    "                                     padding=0,\n",
    "                                     bias=True\n",
    "                                     )\n",
    "        \n",
    "        self.pool1 = torch.nn.AdaptiveMaxPool2d(10)\n",
    "        self.pool2 = torch.nn.AdaptiveMaxPool2d(5)\n",
    "        self.linear1 = torch.nn.Linear(5 * 5 * 16,\n",
    "                                       128, \n",
    "                                       bias=True\n",
    "                                      )\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(128, 1, bias=True)\n",
    "        self.relu    = nn.ReLU()\n",
    "        \n",
    "    def forward(self, xa, xb):\n",
    "        seq_len1, seq_len2 = xa.size()[1], xb.size()[1]\n",
    "        \n",
    "        emb_a, emb_b = self.emb(xa), self.emb(xb)\n",
    "        pad1         = self.max_len - seq_len1\n",
    "        pad2         = self.max_len - seq_len2\n",
    "        simi_img     = torch.matmul(emb_a, emb_b.transpose(1, 2)) / np.sqrt(emb_a.size()[2])\n",
    "        \n",
    "        simi_img = simi_img.unsqueeze(1)\n",
    "        \n",
    "        if pad1 != 0 or pad2 != 0:\n",
    "            simi_img = F.pad(simi_img, (0, pad2, 0, pad1))\n",
    "        \n",
    "        simi_img = self.relu(self.conv1(simi_img))        \n",
    "        simi_img = self.pool1(simi_img)\n",
    "        simi_img = self.relu(self.conv2(simi_img))\n",
    "        simi_img = self.pool2(simi_img)\n",
    "\n",
    "        simi_img = simi_img.squeeze(1).view(xa.size()[0], -1)\n",
    "        \n",
    "        output = self.linear2(F.relu(self.linear1(simi_img)))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.6836, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "m = MatchPyramid(my_vocab, max_len=72).cuda()\n",
    "x = dls.one_batch()\n",
    "out = m(x[0]['pa'], x[0]['pb'])\n",
    "\n",
    "l = BCEWithLogitsLossFlat()\n",
    "res = l(out, x[0]['labels'])\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
